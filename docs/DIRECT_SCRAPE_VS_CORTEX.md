# Direct Scrape vs Cortex CLI - Pourquoi utiliser l'un ou l'autre?

## üéØ Votre Question

> "Quand je passe par scrape_xpath, √ßa passe par l'API OpenAI? C'est absurde, on pourrait pomper l'URL directement sans LLM et aller chercher le texte avec une librairie locale. Pourquoi par l'API on peut pomper wiki mais pas avec un outil maison? Qu'est-ce qu'il manque?"

## ‚úÖ Vous Aviez 100% Raison!

Le scraping **se fait d√©j√† localement** avec `requests` + `lxml` + `elementpath`. L'API LLM n'est utilis√©e que pour:
1. Identifier quel tool appeler
2. Formatter la r√©ponse en markdown

**C'est effectivement absurde de payer pour √ßa!**

## üìä Comparaison: Cortex CLI vs direct_scrape

### Cortex CLI (via LLM)

```bash
python3 cortex.py
mxm> extraire le texte de https://en.wikipedia.org/wiki/Presidium xpath //h1/text()
```

**Flux d'ex√©cution**:
```
User: "extraire texte de wikipedia..."
  ‚Üì
LLM via OpenAI API ($$$) ‚Üê Analyse la requ√™te, identifie le tool
  ‚Üì
scrape_xpath() ‚Üí requests + lxml (LOCAL, GRATUIT!)
  ‚Üì
LLM via OpenAI API ($$$) ‚Üê Formatte la r√©ponse
  ‚Üì
R√©sultat affich√©
```

**Co√ªt**: ~$0.005 par scrape
**Temps**: 5-15 secondes
**Avantages**: Interface conversationnelle, langage naturel
**Inconv√©nients**: Co√ªteux, lent, difficile √† scripter

### direct_scrape (100% local)

```bash
python3 -m cortex.tools.direct_scrape \
  "https://en.wikipedia.org/wiki/Presidium" \
  "//h1/text()"
```

**Flux d'ex√©cution**:
```
User lance la commande
  ‚Üì
scrape_xpath() ‚Üí requests + lxml (LOCAL, GRATUIT!) ‚Üê PAS DE LLM!
  ‚Üì
R√©sultat affich√©
```

**Co√ªt**: $0.00 (100% gratuit!)
**Temps**: 1-3 secondes
**Avantages**: Gratuit, rapide, facile √† scripter
**Inconv√©nients**: Syntaxe XPath requise (pas de langage naturel)

## üìà Tableau Comparatif D√©taill√©

| Aspect | Cortex CLI | direct_scrape | Gagnant |
|--------|------------|---------------|---------|
| **Co√ªt** | ~$0.005/scrape | $0.00 | ‚úÖ direct_scrape |
| **Vitesse** | 5-15s | 1-3s | ‚úÖ direct_scrape |
| **API requise** | OpenAI/DeepSeek | Aucune | ‚úÖ direct_scrape |
| **Langage naturel** | ‚úÖ Oui | ‚ùå Non | ‚úÖ Cortex CLI |
| **Scripting** | Difficile | Facile | ‚úÖ direct_scrape |
| **XPath 2.0** | ‚úÖ Oui | ‚úÖ Oui | √âgalit√© |
| **Stealth crawler** | ‚úÖ Oui | ‚úÖ Oui | √âgalit√© |
| **robots.txt** | Configurable | Configurable | √âgalit√© |
| **Formatting** | Markdown riche | JSON/Text/List | ‚úÖ Cortex CLI |
| **Offline** | ‚ùå Non | ‚úÖ Oui | ‚úÖ direct_scrape |

## üéì Quand Utiliser Quoi?

### Utilisez **Cortex CLI** quand:

‚úÖ Vous voulez utiliser le langage naturel
```
mxm> trouve-moi les titres de HackerNews
mxm> compare les prix sur cette page e-commerce
mxm> r√©sume les 3 premiers paragraphes de Wikipedia
```

‚úÖ Vous voulez une r√©ponse format√©e et contextualis√©e
```
mxm> analyse les tendances des titres HackerNews et identifie les sujets populaires
```

‚úÖ Vous voulez combiner plusieurs outils
```
mxm> scrape wikipedia, extrait les sections, et cr√©e un fichier markdown r√©sum√©
```

‚úÖ Vous explorez et ne connaissez pas l'XPath exact
```
mxm> extraire les informations principales de cette page
```

### Utilisez **direct_scrape** quand:

‚úÖ Vous connaissez l'XPath exact
```bash
python3 -m cortex.tools.direct_scrape URL "//h1/text()"
```

‚úÖ Vous voulez √©conomiser (gratuit vs $0.005)
```bash
# 1000 scrapes: $0 vs $5 avec Cortex CLI
for url in urls.txt; do
  python3 -m cortex.tools.direct_scrape "$url" "//title/text()"
done
```

‚úÖ Vous voulez de la vitesse (1-3s vs 5-15s)
```bash
# Monitoring en temps r√©el
while true; do
  python3 -m cortex.tools.direct_scrape URL XPATH
  sleep 60
done
```

‚úÖ Vous scriptez ou automatisez
```bash
# Cron job pour surveillance
*/5 * * * * python3 -m cortex.tools.direct_scrape URL XPATH -o /var/log/scrape.json
```

‚úÖ Vous travaillez offline (pas de connexion API)
```bash
# Pas besoin d'internet (sauf pour l'URL √† scraper)
python3 -m cortex.tools.direct_scrape "https://example.com" "//text()"
```

## üí° Exemples Concrets

### Exemple 1: Exploration (Cortex CLI)

```bash
python3 cortex.py
mxm> analyse la page wikipedia presidium et dis-moi de quoi √ßa parle
```

**R√©sultat**:
- LLM scrape la page
- LLM analyse le contenu
- LLM g√©n√®re un r√©sum√© contextualis√©
- **Co√ªt**: ~$0.01-0.05
- **Temps**: 10-20s

**Quand**: Vous d√©couvrez un sujet et voulez une analyse rapide

### Exemple 2: Extraction Pr√©cise (direct_scrape)

```bash
python3 -m cortex.tools.direct_scrape \
  "https://en.wikipedia.org/wiki/Presidium" \
  "//h1[@id='firstHeading']/text()"
```

**R√©sultat**:
- Extraction directe du titre
- **Co√ªt**: $0.00
- **Temps**: 1-2s

**Quand**: Vous savez exactement ce que vous voulez extraire

### Exemple 3: Monitoring (direct_scrape)

```bash
#!/bin/bash
# Surveiller les prix toutes les 5 minutes
while true; do
  python3 -m cortex.tools.direct_scrape \
    "https://example-shop.com/product" \
    "//span[@class='price']/text()" \
    -o price_$(date +%Y%m%d_%H%M%S).json
  sleep 300
done
```

**Avantages**:
- Gratuit (vs $288/jour avec Cortex CLI √† 1 req/5min)
- Rapide
- Facilement automatisable

### Exemple 4: Batch Processing (direct_scrape)

```python
# scrape_batch.py
from cortex.tools.direct_scrape import batch_scrape

sources = [
    {"url": "https://site1.com", "xpath": "//title/text()", "name": "Site 1"},
    {"url": "https://site2.com", "xpath": "//h1/text()", "name": "Site 2"},
    {"url": "https://site3.com", "xpath": "//p[1]/text()", "name": "Site 3"},
]

results = batch_scrape(sources, xpath_version="2.0")

# Analyse les r√©sultats
for result in results:
    if result["success"]:
        print(f"{result['source_name']}: {result['count']} elements")
    else:
        print(f"{result['source_name']}: FAILED - {result['error']}")
```

**Co√ªt**: $0.00 (vs $0.015 avec Cortex CLI)

## üîß Guide d'Utilisation de direct_scrape

### Installation

Rien √† installer - d√©j√† inclus dans Cortex!

### Usage de Base

```bash
# Syntaxe
python3 -m cortex.tools.direct_scrape URL XPATH [OPTIONS]

# Exemple simple
python3 -m cortex.tools.direct_scrape \
  "https://example.com" \
  "//h1/text()"
```

### Options Disponibles

```bash
--xpath-version {1.0,2.0}  # Version XPath (default: 2.0)
--format {json,text,list}  # Format de sortie (default: json)
--check-robots             # V√©rifier robots.txt (default: ignore)
-o, --output FILE          # Sauvegarder dans un fichier
```

### Exemples Avanc√©s

#### XPath 2.0 avec string-join

```bash
python3 -m cortex.tools.direct_scrape \
  "https://en.wikipedia.org/wiki/Presidium" \
  "string-join(//p[position() <= 3]//text(), ' ')" \
  --xpath-version 2.0
```

#### Format texte brut

```bash
python3 -m cortex.tools.direct_scrape \
  "https://en.wikipedia.org/wiki/Presidium" \
  "//h1/text()" \
  --format text
```

#### Sauvegarder dans un fichier

```bash
python3 -m cortex.tools.direct_scrape \
  "https://example.com" \
  "//text()" \
  -o output.json
```

#### Mode strict avec robots.txt

```bash
python3 -m cortex.tools.direct_scrape \
  "https://example.com" \
  "//h1/text()" \
  --check-robots
```

## üìä Analyse de Co√ªts R√©els

### Sc√©nario 1: Veille Quotidienne

**T√¢che**: Scraper 100 URLs par jour

**Avec Cortex CLI**:
- Co√ªt: 100 √ó $0.005 = **$0.50/jour**
- Mensuel: **$15/mois**
- Annuel: **$180/an**

**Avec direct_scrape**:
- Co√ªt: 100 √ó $0.00 = **$0.00/jour**
- Mensuel: **$0/mois**
- Annuel: **$0/an**

**√âconomies**: **$180/an**

### Sc√©nario 2: Monitoring Intensif

**T√¢che**: Scraper 1 URL toutes les 5 minutes (288/jour)

**Avec Cortex CLI**:
- Co√ªt: 288 √ó $0.005 = **$1.44/jour**
- Mensuel: **$43.20/mois**
- Annuel: **$518.40/an**

**Avec direct_scrape**:
- Co√ªt: **$0/an**

**√âconomies**: **$518/an**

### Sc√©nario 3: Batch Processing

**T√¢che**: Scraper 10,000 URLs une fois

**Avec Cortex CLI**:
- Co√ªt: 10,000 √ó $0.005 = **$50**
- Temps: 10,000 √ó 10s = ~28 heures

**Avec direct_scrape**:
- Co√ªt: **$0**
- Temps: 10,000 √ó 2s = ~5.5 heures

**√âconomies**: **$50 + 22.5 heures**

## üöÄ Migration de Cortex CLI vers direct_scrape

Si vous utilisez d√©j√† Cortex CLI et voulez √©conomiser:

### Avant (Cortex CLI)

```bash
python3 cortex.py
mxm> extraire le texte de https://example.com xpath //h1/text()
```

### Apr√®s (direct_scrape)

```bash
python3 -m cortex.tools.direct_scrape \
  "https://example.com" \
  "//h1/text()"
```

### Script de Conversion

```bash
#!/bin/bash
# convert_to_direct_scrape.sh

# Remplacer vos appels Cortex CLI par direct_scrape
URL="$1"
XPATH="$2"

# Avant: echo "extraire texte de $URL xpath $XPATH" | python3 cortex.py
# Apr√®s:
python3 -m cortex.tools.direct_scrape "$URL" "$XPATH"
```

## ‚ùì FAQ

### Q: Le scraping √©tait d√©j√† local avec Cortex CLI?

**R**: OUI! Le scraping lui-m√™me (requests + lxml) √©tait d√©j√† local. Mais Cortex CLI ajoute:
1. Appel LLM pour identifier le tool (~$0.002)
2. Appel LLM pour formater la r√©ponse (~$0.003)
3. Total: ~$0.005

`direct_scrape` supprime ces deux appels LLM inutiles.

### Q: Pourquoi Cortex CLI passe par le LLM alors?

**R**: Pour permettre le **langage naturel**:
- "trouve les titres de cette page"
- "compare les prix"
- "r√©sume les 3 premiers paragraphes"

Le LLM traduit √ßa en appels de tools. C'est pratique mais co√ªteux.

### Q: Peut-on utiliser les deux?

**R**: OUI! C'est m√™me recommand√©:
- **Cortex CLI**: Exploration, analyses complexes, langage naturel
- **direct_scrape**: Extraction pr√©cise, automatisation, √©conomies

### Q: direct_scrape est plus limit√©?

**R**: Non! Il a les m√™mes capacit√©s de scraping:
- XPath 2.0 ‚úÖ
- Stealth crawler ‚úÖ
- robots.txt configurable ‚úÖ
- Formats multiples ‚úÖ

Il manque juste:
- Langage naturel ‚ùå
- Formatage Markdown ‚ùå
- Combinaison multi-tools ‚ùå

### Q: Comment d√©bugger mes XPaths?

**R**: Testez avec direct_scrape d'abord (gratuit et rapide):

```bash
# Test rapide
python3 -m cortex.tools.direct_scrape URL "//h1" --format text

# Si √ßa ne fonctionne pas
python3 -m cortex.tools.direct_scrape URL "//h1/text()" --format text

# XPath 2.0
python3 -m cortex.tools.direct_scrape URL "//h1[1]/text()" --xpath-version 2.0
```

Une fois l'XPath valid√©, utilisez-le dans Cortex CLI si besoin de langage naturel.

## üéØ Conclusion

### TL;DR

| Si vous voulez... | Utilisez... |
|-------------------|-------------|
| Langage naturel | Cortex CLI |
| √âconomiser de l'argent | direct_scrape |
| √ätre rapide | direct_scrape |
| Explorer un site | Cortex CLI |
| Scripter/automatiser | direct_scrape |
| Analyses complexes | Cortex CLI |
| Extraction simple | direct_scrape |
| Travailler offline | direct_scrape |

### Le Meilleur des Deux Mondes

1. **Explorez avec Cortex CLI** (langage naturel)
   ```
   mxm> trouve les informations principales de cette page
   ```

2. **Notez l'XPath exact** que Cortex CLI a utilis√©

3. **Automatisez avec direct_scrape** (gratuit)
   ```bash
   python3 -m cortex.tools.direct_scrape URL "XPATH_EXACT"
   ```

### R√©ponse Finale

**Ce qui manquait**: Un outil CLI direct qui ne passe pas par le LLM.

**Maintenant vous l'avez**: `direct_scrape` - 100% local, 100% gratuit, XPath 2.0!

---

**Derni√®re mise √† jour**: 2025-10-15
**Version**: 1.0
**Auteur**: Cortex MXMCorp
