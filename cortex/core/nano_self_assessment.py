"""
Nano Self-Assessment System

Permet √† nano d'√©valuer sa propre capacit√© √† g√©rer une t√¢che et de router
intelligemment vers l'employ√© le plus qualifi√© si n√©cessaire.

Flow:
1. Nano √©value: confidence + severity + best_employee
2. D√©cision: peut-il g√©rer SAFE avec HAUTE confiance?
3. Si OUI ‚Üí ex√©cute
4. Si NON ‚Üí route vers employ√© qualifi√© avec contexte adapt√©
"""

import json
from typing import Dict, Any, Optional, Tuple
from enum import Enum
from dataclasses import dataclass

from cortex.core.llm_client import LLMClient
from cortex.core.model_router import ModelTier
from cortex.core.smart_context_builder import TaskSeverity


class ConfidenceLevel(Enum):
    """Niveau de confiance de nano pour g√©rer une t√¢che"""
    HIGH = "HIGH"      # Peut g√©rer facilement
    MEDIUM = "MEDIUM"  # Peut g√©rer mais attention requise
    LOW = "LOW"        # Ne devrait pas g√©rer


@dataclass
class TaskAssessment:
    """√âvaluation d'une t√¢che par nano"""
    confidence: ConfidenceLevel
    severity: TaskSeverity
    can_handle_safely: bool
    best_employee: str
    reasoning: str

    def to_dict(self) -> Dict[str, Any]:
        return {
            "confidence": self.confidence.value,
            "severity": self.severity.value,
            "can_handle_safely": self.can_handle_safely,
            "best_employee": self.best_employee,
            "reasoning": self.reasoning
        }


SELF_ASSESSMENT_PROMPT = """You are a task evaluator for nano model. Analyze this task and provide a structured assessment.

Task: {task}

Evaluate these aspects:

1. CONFIDENCE: Can nano handle this task safely with HIGH confidence?
   - HIGH: Simple, routine task (comments, formatting, simple functions, basic validation)
   - MEDIUM: Doable but requires careful attention (moderate complexity)
   - LOW: Complex, risky, or outside expertise (architecture, security, complex algorithms)

2. SEVERITY: What's the severity level?
   - CRITICAL: Production changes, security (auth/encryption), payments, database migrations, API keys
   - HIGH: Public APIs, core features, important user-facing functionality
   - MEDIUM: Standard features, general improvements, internal tools
   - LOW: Refactoring, documentation, tests, cleanup, comments

3. BEST_EMPLOYEE: If nano cannot handle with HIGH confidence, who is most qualified?
   - nano: Simple task, nano can handle
   - ceo: Strategic decisions, company-wide changes, high-level planning
   - cto: Technical architecture, system design, complex technical decisions
   - hr: Hiring, employee management, team structure, org design
   - finance: Budget, pricing, cost analysis, financial planning
   - product: Features, roadmap, user experience, product decisions
   - [specific_worker]: Implementation tasks requiring specific expertise

4. REASONING: Brief explanation (1-2 sentences max)

IMPORTANT RULES:
- Be CONSERVATIVE: When in doubt, delegate
- ALWAYS delegate CRITICAL tasks (regardless of confidence)
- ALWAYS delegate if confidence is LOW
- nano should only handle HIGH confidence + (LOW or MEDIUM severity)

Respond ONLY with valid JSON (no markdown, no extra text):
{{
  "confidence": "HIGH|MEDIUM|LOW",
  "severity": "CRITICAL|HIGH|MEDIUM|LOW",
  "can_handle_safely": true|false,
  "best_employee": "nano|ceo|cto|hr|finance|product|[worker_name]",
  "reasoning": "brief explanation"
}}"""


class NanoSelfAssessment:
    """
    Syst√®me d'auto-√©valuation pour nano

    Permet √† nano de d√©terminer s'il peut g√©rer une t√¢che en s√©curit√©
    ou s'il doit la d√©l√©guer √† un employ√© plus qualifi√©.
    """

    def __init__(self, llm_client: LLMClient, use_tier: ModelTier = ModelTier.NANO):
        """
        Args:
            llm_client: Client LLM pour communication avec nano
            use_tier: Quel tier utiliser pour l'√©valuation (default: NANO)
        """
        self.llm = llm_client
        self.tier = use_tier

    def evaluate(self, task: str, verbose: bool = False) -> TaskAssessment:
        """
        √âvalue si nano peut g√©rer la t√¢che en s√©curit√©

        Args:
            task: Description de la t√¢che
            verbose: Si True, affiche les d√©tails

        Returns:
            TaskAssessment avec confidence, severity, routing, etc.
        """
        if verbose:
            print(f"üîç Nano evaluating: {task[:60]}...")

        # Construire le prompt
        prompt = SELF_ASSESSMENT_PROMPT.format(task=task)

        # Demander √† nano d'√©valuer
        try:
            llm_response = self.llm.complete(
                messages=[{"role": "user", "content": prompt}],
                tier=self.tier,
                max_tokens=200,
                temperature=1.0  # Nano ne supporte que temperature=1.0
            )

            response = llm_response.content

            # Parser la r√©ponse JSON
            assessment_data = self._parse_response(response)

            # Appliquer les r√®gles de s√©curit√©
            assessment_data = self._apply_safety_rules(assessment_data)

            # Cr√©er l'objet TaskAssessment
            assessment = TaskAssessment(
                confidence=ConfidenceLevel[assessment_data["confidence"]],
                severity=TaskSeverity[assessment_data["severity"]],
                can_handle_safely=assessment_data["can_handle_safely"],
                best_employee=assessment_data["best_employee"],
                reasoning=assessment_data["reasoning"]
            )

            if verbose:
                self._print_assessment(assessment)

            return assessment

        except Exception as e:
            # En cas d'erreur, d√©l√©guer par d√©faut (conservateur)
            print(f"‚ö†Ô∏è  Assessment error: {e}")
            return TaskAssessment(
                confidence=ConfidenceLevel.LOW,
                severity=TaskSeverity.MEDIUM,
                can_handle_safely=False,
                best_employee="ceo",
                reasoning=f"Assessment failed: {str(e)}"
            )

    def _parse_response(self, response: str) -> Dict[str, Any]:
        """Parse la r√©ponse JSON de nano"""
        try:
            # Nettoyer la r√©ponse (enlever markdown si pr√©sent)
            cleaned = response.strip()
            if cleaned.startswith("```"):
                # Extraire JSON du markdown
                lines = cleaned.split("\n")
                cleaned = "\n".join(lines[1:-1])

            return json.loads(cleaned)

        except json.JSONDecodeError as e:
            raise ValueError(f"Invalid JSON response: {response}") from e

    def _apply_safety_rules(self, assessment: Dict[str, Any]) -> Dict[str, Any]:
        """
        Applique les r√®gles de s√©curit√© strictes

        R√®gles:
        1. Toute t√¢che CRITICAL ‚Üí must delegate
        2. Confidence LOW ‚Üí must delegate
        3. Confidence MEDIUM + Severity HIGH ‚Üí should delegate
        """
        severity = assessment["severity"]
        confidence = assessment["confidence"]

        # R√®gle 1: CRITICAL tasks must be delegated
        if severity == "CRITICAL":
            assessment["can_handle_safely"] = False
            if assessment["best_employee"] == "nano":
                assessment["best_employee"] = "cto"  # Default for critical

        # R√®gle 2: LOW confidence must be delegated
        elif confidence == "LOW":
            assessment["can_handle_safely"] = False

        # R√®gle 3: MEDIUM confidence + HIGH severity ‚Üí delegate
        elif confidence == "MEDIUM" and severity == "HIGH":
            assessment["can_handle_safely"] = False

        # R√®gle 4: HIGH confidence + (LOW or MEDIUM) ‚Üí can handle
        elif confidence == "HIGH" and severity in ["LOW", "MEDIUM"]:
            assessment["can_handle_safely"] = True
            assessment["best_employee"] = "nano"

        else:
            # Par d√©faut: √™tre conservateur
            assessment["can_handle_safely"] = False

        return assessment

    def _print_assessment(self, assessment: TaskAssessment):
        """Affiche l'√©valuation de mani√®re lisible"""
        print(f"\nüìä Nano Assessment:")
        print(f"   Confidence: {assessment.confidence.value}")
        print(f"   Severity: {assessment.severity.value}")
        print(f"   Can handle safely: {'‚úÖ YES' if assessment.can_handle_safely else '‚ùå NO'}")
        print(f"   Best employee: {assessment.best_employee}")
        print(f"   Reasoning: {assessment.reasoning}")

    def should_handle(self, task: str) -> bool:
        """
        D√©termine rapidement si nano devrait g√©rer la t√¢che

        Args:
            task: Description de la t√¢che

        Returns:
            True si nano peut g√©rer en s√©curit√©
        """
        assessment = self.evaluate(task)
        return assessment.can_handle_safely


class IntelligentRouter:
    """
    Routeur intelligent bas√© sur l'√©valuation de nano

    Route les t√¢ches vers le bon employ√© avec le contexte adapt√©
    selon la s√©v√©rit√© d√©tect√©e.
    """

    def __init__(self, nano_assessment: NanoSelfAssessment):
        """
        Args:
            nano_assessment: Syst√®me d'√©valuation nano
        """
        self.nano_assessment = nano_assessment

    def get_routing_decision(
        self,
        task: str,
        verbose: bool = False
    ) -> Tuple[str, Dict[str, Any]]:
        """
        D√©cide du routing pour une t√¢che

        Args:
            task: Description de la t√¢che
            verbose: Si True, affiche les d√©tails

        Returns:
            Tuple (employee_name, execution_params)
        """
        # Phase 1: √âvaluation par nano
        assessment = self.nano_assessment.evaluate(task, verbose=verbose)

        # Phase 2: D√©cision de routing
        if assessment.can_handle_safely:
            # Nano peut g√©rer
            employee = "nano"
            params = self._get_nano_params(assessment)

            if verbose:
                print(f"\n‚úÖ Decision: NANO handles (safe)")

        else:
            # D√©l√©guer au meilleur employ√©
            employee = assessment.best_employee

            # Fallback si employ√© inconnu
            if employee == "nano":
                employee = "ceo"

            params = self._get_delegate_params(assessment)

            if verbose:
                print(f"\nüîÑ Decision: DELEGATE to {employee}")

        return employee, params

    def _get_nano_params(self, assessment: TaskAssessment) -> Dict[str, Any]:
        """Param√®tres d'ex√©cution pour nano"""
        return {
            "severity": assessment.severity,
            "context_budget": 900,  # Budget standard pour nano
            "assessment": assessment.to_dict(),
            "executor": "nano"
        }

    def _get_delegate_params(self, assessment: TaskAssessment) -> Dict[str, Any]:
        """Param√®tres d'ex√©cution pour employ√© d√©l√©gu√©"""

        # Ajuster le budget selon s√©v√©rit√©
        budget_map = {
            TaskSeverity.CRITICAL: 600,  # Strict, peu de tokens
            TaskSeverity.HIGH: 800,
            TaskSeverity.MEDIUM: 900,
            TaskSeverity.LOW: 900
        }

        return {
            "severity": assessment.severity,
            "context_budget": budget_map[assessment.severity],
            "assessment": assessment.to_dict(),
            "delegated_from": "nano",
            "delegation_reason": assessment.reasoning
        }


if __name__ == "__main__":
    # Test rapide
    print("Testing Nano Self-Assessment...\n")

    client = LLMClient()
    nano_eval = NanoSelfAssessment(client)
    router = IntelligentRouter(nano_eval)

    # Test cases
    test_tasks = [
        "Add a comment to the calculate_total function",
        "Fix critical authentication vulnerability in production",
        "Create a new dashboard feature for analytics",
        "Refactor code and add documentation",
        "Redesign the system architecture",
    ]

    for task in test_tasks:
        print("=" * 70)
        print(f"Task: {task}")
        print("=" * 70)

        employee, params = router.get_routing_decision(task, verbose=True)

        print(f"\nüéØ Final Decision:")
        print(f"   Employee: {employee}")
        print(f"   Severity: {params['severity'].value}")
        print(f"   Context Budget: {params['context_budget']} tokens")
        print()
