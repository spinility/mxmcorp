"""
Communications Agent - Responsable de la communication avec l'utilisateur

ROLE: COMMUNICATIONS (Synthesis + Reporting) - Niveau 2 de la hi√©rarchie
TIER: NANO pour r√©sum√©s rapides et √©conomiques

NOUVEAU WORKFLOW:
1. Re√ßoit logs filtr√©s du workflow (via LogFilterService)
2. R√©sume le "thinking" de Cortex: d√©cisions prises, alternatives consid√©r√©es
3. Pr√©sente de mani√®re claire pour que l'utilisateur comprenne le raisonnement
4. Facilite feedback: "voici ce qui a √©t√© fait, qu'auriez-vous pr√©f√©r√©?"

Responsabilit√©s:
- R√©sumer workflows de requ√™tes avec thinking transparent
- Expliquer d√©cisions des agents (pourquoi X au lieu de Y)
- Pr√©senter alternatives consid√©r√©es mais non choisies
- Faciliter feedback utilisateur sur le raisonnement
- Formater recommandations du Tooler (fonctionnalit√© existante)

D√©clench√©:
- Apr√®s chaque requ√™te utilisateur compl√©t√©e
- Sur demande utilisateur ("explique-moi ce qui s'est pass√©")
- En fin de git_integration_workflow
"""

from typing import Dict, Any, List, Optional
from datetime import datetime
import time
from cortex.core.llm_client import LLMClient, ModelTier
from cortex.core.agent_hierarchy import DecisionAgent, AgentRole, AgentResult, EscalationContext
from cortex.services.log_filter_service import get_log_filter_service
from cortex.core.agent_memory import get_agent_memory


class CommunicationsAgent(DecisionAgent):
    """Agent responsable de communiquer avec l'utilisateur"""

    def __init__(self, llm_client: LLMClient):
        """
        Initialize Communications Agent

        Args:
            llm_client: LLM client for crafting responses
        """
        super().__init__(llm_client, specialization="communications")
        self.log_filter = get_log_filter_service()
        self.memory = get_agent_memory('communication', 'communications')

    def craft_recommendation(
        self,
        tooler_request: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Cr√©e une recommandation claire pour l'utilisateur

        Args:
            tooler_request: Requ√™te du Tooler avec les r√©sultats de recherche

        Returns:
            Recommandation format√©e pour l'utilisateur
        """
        start_time = time.time()

        prompt = f"""Tu es un expert en communication technique.
Tu dois expliquer clairement √† l'utilisateur ce qui peut √™tre fait.

CONTEXTE:
Requ√™te utilisateur: "{tooler_request['user_request']}"
Capacit√© manquante: {tooler_request['capability_needed']}

RECHERCHE DU TOOLER:
{tooler_request['research_findings']}

TA MISSION:
Cr√©e un message clair pour l'utilisateur avec:
1. Ce que Cortex ne peut pas faire actuellement
2. Les solutions qui existent
3. Les prochaines √©tapes recommand√©es

TON: {tooler_request['tone']} - Sois utile, positif, et actionnable

FORMAT (utilise les emojis):
üéØ **Situation:** [Explication courte de ce qui manque]

üîç **Solutions trouv√©es:** [2-3 options avec noms d'outils/packages]

üí° **Recommandation:** [Action concr√®te que l'utilisateur peut prendre]

‚öôÔ∏è **Prochaines √©tapes:**
- [√âtape 1]
- [√âtape 2]
- [Optionnel: √âtape 3]

Sois concis (max 150 mots) mais informatif."""

        messages = [
            {"role": "system", "content": prompt},
            {"role": "user", "content": "Cr√©e la recommandation"}
        ]

        # Utiliser DeepSeek pour la communication (bon √©quilibre)
        response = self.llm_client.complete(
            messages=messages,
            tier=ModelTier.DEEPSEEK,
            max_tokens=500,
            temperature=0.8
        )

        result = {
            "recommendation_ready": True,
            "message": response.content,
            "model_used": response.model,
            "cost": response.cost
        }

        # Record to memory
        duration = time.time() - start_time
        self.memory.record_execution(
            request=f"Craft recommendation: {tooler_request.get('capability_needed', 'Unknown')}",
            result=result,
            duration=duration,
            cost=response.cost
        )

        # Update state
        self.memory.update_state({
            'last_recommendation_timestamp': datetime.now().isoformat(),
            'last_capability_needed': tooler_request.get('capability_needed')
        })

        # Detect patterns in capability types
        self.memory.add_pattern(
            f'capability_needed_{tooler_request.get("capability_needed", "unknown")}',
            {
                'capability': tooler_request.get('capability_needed'),
                'tone': tooler_request.get('tone'),
                'user_request': tooler_request.get('user_request', '')[:100]
            }
        )

        return result

    def can_handle(self, request: str, context: Optional[Dict] = None) -> float:
        """
        √âvalue si le CommunicationsAgent peut g√©rer la requ√™te

        Keywords: explain, summary, workflow, thinking, what happened, why
        """
        request_lower = request.lower()

        comm_keywords = [
            'explain', 'summary', 'workflow', 'thinking',
            'what happened', 'why did', 'how did',
            'summarize', 'tell me about', 'show me'
        ]

        # Haute confiance si contient keywords
        if any(kw in request_lower for kw in comm_keywords):
            return 0.9

        return 0.0

    def execute(
        self,
        request: str,
        context: Optional[Dict] = None,
        escalation_context: Optional[EscalationContext] = None
    ) -> AgentResult:
        """
        Ex√©cute une op√©ration de communication

        Args:
            request: Requ√™te utilisateur
            context: Contexte avec session_start, agents_involved, etc.
            escalation_context: Contexte si escalation

        Returns:
            AgentResult avec r√©sum√©/explication
        """
        # D√©terminer le type de communication demand√©
        if 'workflow' in request.lower() or 'summary' in request.lower():
            result = self.summarize_workflow(context)
        elif 'explain' in request.lower() or 'why' in request.lower():
            result = self.explain_agent_decision(request, context)
        else:
            # Fallback: r√©sum√© g√©n√©ral
            result = self.summarize_workflow(context)

        return AgentResult(
            success=result['success'],
            role=self.role,
            tier=self.tier,
            content=result,
            cost=result.get('cost', 0.0),
            confidence=0.85,
            should_escalate=False,
            escalation_reason=None,
            error=result.get('error'),
            metadata={'communication_result': result}
        )

    def summarize_workflow(
        self,
        context: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """
        R√©sume le workflow d'une requ√™te avec thinking transparent

        Args:
            context: Contexte avec:
                - session_start: D√©but de la session
                - request: Requ√™te utilisateur originale
                - agents_involved: Liste des agents impliqu√©s
                - focus: 'all', 'planning', 'execution', 'testing'

        Returns:
            Dict avec:
                - summary: R√©sum√© du workflow
                - thinking: D√©tails du raisonnement
                - decisions: D√©cisions cl√©s prises
                - alternatives: Alternatives consid√©r√©es
                - feedback_prompt: Question pour feedback utilisateur
        """
        start_time = time.time()

        try:
            print(f"\n{'='*70}")
            print(f"üí¨ COMMUNICATIONS AGENT - Workflow Summary")
            print(f"{'='*70}\n")

            # R√©cup√©rer les logs pertinents
            session_start = context.get('session_start') if context else None
            if not session_start:
                session_start = datetime.now()

            logs = self.log_filter.get_workflow_logs(
                session_start=session_start,
                limit=100
            )

            if not logs:
                return {
                    'success': True,
                    'summary': "Aucun workflow r√©cent d√©tect√©.",
                    'thinking': {},
                    'decisions': [],
                    'alternatives': [],
                    'feedback_prompt': None,
                    'cost': 0.0
                }

            # Analyser les logs pour extraire thinking
            thinking_analysis = self._analyze_thinking(logs)

            # Construire le r√©sum√© avec NANO LLM
            summary_text = self._generate_summary(logs, thinking_analysis, context)

            # Extraire d√©cisions cl√©s
            key_decisions = self._extract_key_decisions(logs)

            # Extraire alternatives consid√©r√©es
            alternatives = self._extract_alternatives(logs, thinking_analysis)

            # G√©n√©rer question pour feedback
            feedback_prompt = self._generate_feedback_prompt(key_decisions, alternatives)

            print(f"\n{'='*70}")
            print(f"Summary Generated:")
            print(f"  Logs analyzed: {len(logs)}")
            print(f"  Key decisions: {len(key_decisions)}")
            print(f"  Alternatives found: {len(alternatives)}")
            print(f"{'='*70}\n")

            result = {
                'success': True,
                'action': 'summarize_workflow',
                'summary': summary_text,
                'thinking': thinking_analysis,
                'decisions': key_decisions,
                'alternatives': alternatives,
                'feedback_prompt': feedback_prompt,
                'logs_analyzed': len(logs),
                'cost': 0.0001  # NANO cost estimate
            }

            # Record to memory
            duration = time.time() - start_time
            self.memory.record_execution(
                request=f"Summarize workflow: {len(logs)} logs analyzed",
                result=result,
                duration=duration,
                cost=result['cost']
            )

            # Update state
            self.memory.update_state({
                'last_summary_timestamp': datetime.now().isoformat(),
                'logs_analyzed': len(logs),
                'key_decisions_count': len(key_decisions),
                'alternatives_count': len(alternatives)
            })

            # Detect patterns in workflow types
            agents_involved = set(log.get('author', 'Unknown') for log in logs)
            for agent in agents_involved:
                self.memory.add_pattern(
                    f'agent_involved_{agent}',
                    {
                        'agent': agent,
                        'logs_count': sum(1 for log in logs if log.get('author') == agent)
                    }
                )

            return result

        except Exception as e:
            duration = time.time() - start_time
            result = {
                'success': False,
                'action': 'summarize_workflow',
                'error': f"Workflow summary failed: {str(e)}",
                'cost': 0.0
            }

            # Record failure to memory
            self.memory.record_execution(
                request="Summarize workflow",
                result=result,
                duration=duration,
                cost=0.0
            )

            return result

    def _analyze_thinking(self, logs: List[Dict]) -> Dict[str, Any]:
        """
        Analyse les logs pour extraire le "thinking" de Cortex

        Returns:
            Dict avec:
                - planning: Logs de planification
                - execution: Logs d'ex√©cution
                - testing: Logs de tests
                - escalations: Logs d'escalations
        """
        thinking = {
            'planning': [],
            'execution': [],
            'testing': [],
            'escalations': [],
            'errors': []
        }

        for log in logs:
            change_type = log.get('change_type', '')

            if 'plan' in change_type or 'decision' in change_type:
                thinking['planning'].append(log)
            elif 'execution' in change_type or 'update' in change_type:
                thinking['execution'].append(log)
            elif 'test' in change_type:
                thinking['testing'].append(log)
            elif 'escalation' in change_type:
                thinking['escalations'].append(log)
            elif 'fail' in change_type or 'error' in change_type:
                thinking['errors'].append(log)

        return thinking

    def _generate_summary(
        self,
        logs: List[Dict],
        thinking: Dict[str, Any],
        context: Optional[Dict]
    ) -> str:
        """
        G√©n√®re un r√©sum√© textuel avec NANO LLM

        Returns:
            R√©sum√© format√© en markdown
        """
        # Pr√©parer un r√©sum√© compact des logs pour NANO
        log_summary = {
            'total_logs': len(logs),
            'planning_steps': len(thinking['planning']),
            'execution_steps': len(thinking['execution']),
            'test_steps': len(thinking['testing']),
            'escalations': len(thinking['escalations']),
            'errors': len(thinking['errors'])
        }

        # Extraire agents impliqu√©s
        agents = set(log.get('author', 'Unknown') for log in logs)

        prompt = f"""Tu es le Communications Agent de Cortex. R√©sume ce workflow de mani√®re claire et concise.

WORKFLOW STATS:
- Logs totaux: {log_summary['total_logs']}
- Agents impliqu√©s: {', '.join(agents)}
- Planning: {log_summary['planning_steps']} d√©cisions
- Ex√©cution: {log_summary['execution_steps']} actions
- Tests: {log_summary['test_steps']} v√©rifications
- Escalations: {log_summary['escalations']}
- Erreurs: {log_summary['errors']}

R√âSUM√â (max 100 mots, markdown):
- Commence par "üß† **Thinking de Cortex:**"
- Explique le flux: planning ‚Üí ex√©cution ‚Üí tests
- Mentionne d√©cisions cl√©s et agents responsables
- Sois clair et concis"""

        try:
            response = self.llm_client.complete(
                messages=[{"role": "user", "content": prompt}],
                tier=ModelTier.NANO,
                max_tokens=200
            )
            return response.content

        except Exception as e:
            # Fallback: r√©sum√© basique
            return f"""üß† **Thinking de Cortex:**

{log_summary['planning_steps']} d√©cisions de planification ont √©t√© prises par {', '.join(agents)}.
{log_summary['execution_steps']} actions ont √©t√© ex√©cut√©es.
{log_summary['test_steps']} v√©rifications de tests ont √©t√© effectu√©es.
{log_summary['errors']} erreurs ont √©t√© rencontr√©es."""

    def _extract_key_decisions(self, logs: List[Dict]) -> List[Dict[str, Any]]:
        """
        Extrait les d√©cisions cl√©s du workflow

        Returns:
            Liste de d√©cisions avec agent, description, rationale
        """
        key_decisions = []

        decision_types = [
            'harmonization_plan', 'test_analysis', 'execution_start',
            'agent_decision', 'agent_escalation'
        ]

        for log in logs:
            if log.get('change_type') in decision_types:
                key_decisions.append({
                    'agent': log.get('author', 'Unknown'),
                    'decision': log.get('description', ''),
                    'timestamp': log.get('timestamp'),
                    'impact': log.get('impact_level', 'medium'),
                    'metadata': log.get('metadata', {})
                })

        return key_decisions

    def _extract_alternatives(
        self,
        logs: List[Dict],
        thinking: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        Extrait les alternatives consid√©r√©es mais non choisies

        Returns:
            Liste d'alternatives avec description
        """
        alternatives = []

        # Chercher dans les metadata des logs de planification
        for log in thinking['planning']:
            metadata = log.get('metadata', {})

            # HarmonizationAgent inclut alternatives dans ses plans
            if 'alternatives' in metadata:
                alternatives.append({
                    'context': log.get('description'),
                    'alternatives': metadata['alternatives'],
                    'chosen': 'Plan principal s√©lectionn√©'
                })

        return alternatives

    def _generate_feedback_prompt(
        self,
        decisions: List[Dict],
        alternatives: List[Dict]
    ) -> str:
        """
        G√©n√®re une question pour solliciter feedback utilisateur

        Returns:
            Question format√©e en markdown
        """
        if not decisions:
            return "‚úÖ Workflow compl√©t√©. Avez-vous des commentaires ou suggestions?"

        # R√©sumer les d√©cisions cl√©s
        decision_summary = []
        for idx, decision in enumerate(decisions[:3], 1):
            agent = decision['agent']
            desc = decision['decision'][:80]
            decision_summary.append(f"{idx}. **{agent}**: {desc}")

        summary_text = "\n".join(decision_summary)

        prompt = f"""üí≠ **Feedback souhait√©:**

Voici les d√©cisions cl√©s prises par Cortex:

{summary_text}

**Question:** Est-ce que ces d√©cisions vous semblent appropri√©es? Auriez-vous pr√©f√©r√© une approche diff√©rente?"""

        return prompt

    def explain_agent_decision(
        self,
        request: str,
        context: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """
        Explique une d√©cision sp√©cifique d'un agent

        Args:
            request: Requ√™te utilisateur demandant explication
            context: Contexte

        Returns:
            Dict avec explication d√©taill√©e
        """
        start_time = time.time()

        try:
            # R√©cup√©rer les logs thinking
            logs = self.log_filter.get_agent_thinking_logs(
                agent_name=None,  # Tous les agents
                time_period='recent',
                limit=50
            )

            # Trouver la d√©cision la plus pertinente √† la requ√™te
            # (pour simplification, on prend la plus r√©cente)
            if not logs:
                return {
                    'success': True,
                    'explanation': "Aucune d√©cision r√©cente √† expliquer.",
                    'cost': 0.0
                }

            recent_decision = logs[0]

            explanation = f"""üîç **Explication de d√©cision:**

**Agent:** {recent_decision.get('author')}
**D√©cision:** {recent_decision.get('description')}
**Timestamp:** {recent_decision.get('timestamp')}
**Impact:** {recent_decision.get('impact_level')}

**Contexte:** {recent_decision.get('metadata', {}).get('context', 'N/A')}

**Rationale:** Cette d√©cision a √©t√© prise pour {recent_decision.get('description')}"""

            result = {
                'success': True,
                'action': 'explain_decision',
                'explanation': explanation,
                'decision': recent_decision,
                'cost': 0.0
            }

            # Record to memory
            duration = time.time() - start_time
            self.memory.record_execution(
                request=f"Explain decision: {recent_decision.get('author', 'Unknown')}",
                result=result,
                duration=duration,
                cost=0.0
            )

            # Update state
            self.memory.update_state({
                'last_explanation_timestamp': datetime.now().isoformat(),
                'last_decision_explained': recent_decision.get('description', '')[:100]
            })

            # Detect patterns in decision types explained
            self.memory.add_pattern(
                f'decision_type_{recent_decision.get("change_type", "unknown")}',
                {
                    'agent': recent_decision.get('author'),
                    'change_type': recent_decision.get('change_type'),
                    'impact': recent_decision.get('impact_level')
                }
            )

            return result

        except Exception as e:
            duration = time.time() - start_time
            result = {
                'success': False,
                'action': 'explain_decision',
                'error': f"Decision explanation failed: {str(e)}",
                'cost': 0.0
            }

            # Record failure to memory
            self.memory.record_execution(
                request="Explain decision",
                result=result,
                duration=duration,
                cost=0.0
            )

            return result


def create_communications_agent(llm_client: LLMClient) -> CommunicationsAgent:
    """Factory function to create a Communications Agent"""
    return CommunicationsAgent(llm_client)
